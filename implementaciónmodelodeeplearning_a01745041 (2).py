# -*- coding: utf-8 -*-
"""ImplementaciónModeloDeepLearning_A01745041.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1clNWssJjeQQ9gb20iFhJ1lvmVfSbh4py

# **Introducción**

Para este proyecto, se decidió utilizar el dataset de Brain Tumor. Cómo se sabe, las personas con mejor tasa de recuperación de un cáncer cerebral son aquellas que pudieron ser diagnosticadas de manera temprana. Es por esto por lo que el enfoque de este proyecto es en la diagnosticación temprana de tumores cerebrales.

El área de la medicina es relevante en el área de la computación y de los modelos predictivos ya que ofrece la capacidad de entrenar modelos con características claras. Es decir; las CNN son capaces de aprender automáticamente características relevantes de las imágenes, sin necesidad de una extracción manual de características. También,  las CNN pueden aprender jerarquías de características, desde características simples a complejas, lo que es beneficioso para la detección de tumores.

# ***Datos***
"""

#OS libs
import os
import shutil
import itertools
import pathlib
from PIL import Image

#Data handling tools
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('whitegrid')
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix , classification_report

#Deep learning libs
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam , Adamax
from tensorflow.keras import regularizers

#Warningds
import warnings
warnings.filterwarnings('ignore')

from google.colab import files

# Sube el archivo kaggle.json que descargaste
uploaded = files.upload()

# Mueve el archivo a la ubicación adecuada
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset

!unzip brain-tumor-mri-dataset.zip

train_data_path = '/content/Training'

filepaths =[]
labels = []

folds = os.listdir(train_data_path)

for fold in folds:
    f_path = os.path.join(train_data_path , fold)
    filelists = os.listdir(f_path)

    for file in filelists:
        filepaths.append(os.path.join(f_path , file))
        labels.append(fold)

#Concat data paths with labels
Fseries = pd.Series(filepaths , name = 'filepaths')
Lseries = pd.Series(labels , name = 'label')
train_df = pd.concat([Fseries , Lseries] , axis = 1)

train_df

test_data_path = '/content/Testing'

filepaths =[]
labels = []

folds = os.listdir(test_data_path)

for fold in folds:
    f_path = os.path.join(test_data_path , fold)
    filelists = os.listdir(f_path)

    for file in filelists:
        filepaths.append(os.path.join(f_path , file))
        labels.append(fold)

#Concat data paths with labels
Fseries = pd.Series(filepaths , name = 'filepaths')
Lseries = pd.Series(labels , name = 'label')
test_df = pd.concat([Fseries , Lseries] , axis = 1)

test_df

valid , test = train_test_split(test_df , train_size = 0.5 , shuffle = True , random_state= 42)

img_size = (224 ,244)
batch_size = 16

tr_gen = ImageDataGenerator()
ts_gen= ImageDataGenerator()

train_gen = tr_gen.flow_from_dataframe(train_df , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,
                                      class_mode = 'categorical' , color_mode = 'rgb' , shuffle = True , batch_size =batch_size)

valid_gen = ts_gen.flow_from_dataframe(valid , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,
                                       class_mode = 'categorical',color_mode = 'rgb' , shuffle= True, batch_size = batch_size)

test_gen = ts_gen.flow_from_dataframe(test , x_col= 'filepaths' , y_col = 'label' , target_size = img_size ,
                                      class_mode = 'categorical' , color_mode= 'rgb' , shuffle = False , batch_size = batch_size)

"""# **Desarrollo de Modelo**"""

model = Sequential()

# Primer bloque convolucional
model.add(Conv2D(32, (3, 3), input_shape=(img_size[0], img_size[1], 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Segundo bloque convolucional
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Tercer bloque convolucional
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Cuarto bloque convolucional
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten para conectar a capas densas
model.add(Flatten())

# Capa densa con 256 neuronas y activación relu
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))  # Dropout para evitar el sobreajuste

# Capa de salida con activación softmax para la clasificación
model.add(Dense(len(train_df['label'].unique()), activation='softmax'))

# Compilar el modelo
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Muestra un resumen del modelo
model.summary()

epochs = 5  # Ajusta el número de épocas según sea necesario

history = model.fit(
    train_gen,
    steps_per_epoch=train_gen.n // batch_size,
    epochs=epochs,
    validation_data=valid_gen,
    validation_steps=valid_gen.n // batch_size
)

train_acc = history.history['accuracy']
train_loss = history.history['loss']

val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

index_loss = np.argmin(val_loss)
val_lowest = val_loss[index_loss]

index_acc = np.argmax(val_acc)
val_highest = val_acc[index_acc]

Epochs = [i+1 for i in range(len(train_acc))]

loss_label = f'Best epochs = {str(index_loss +1)}'
acc_label = f'Best epochs = {str(index_acc + 1)}'

plt.figure(figsize= (20,8))
plt.style.use('fivethirtyeight')

plt.subplot(1,2,1)
plt.plot(Epochs , train_loss , 'r' , label = 'Training Loss')
plt.plot(Epochs , val_loss , 'g' , label = 'Validation Loss')
plt.scatter(index_loss + 1 , val_lowest , s = 150 , c = 'blue',label = loss_label)
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1,2,2)
plt.plot(Epochs , train_acc , 'r' , label = 'Training Accuracy')
plt.plot(Epochs , val_acc , 'g' , label = 'Validation Accuracy')
plt.scatter(index_acc + 1 , val_highest , s = 150 , c = 'blue',label = acc_label)
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout
plt.show();

"""# **Ajuste del Modelo**

Ya que el modelo tarda demasiado tiempo en correr, pienso que puede llegar a ser ineficiente y poco óptimo. Para esto, se decidió disminuir las capas de la red.

También, se decidió cambiar y hacer un ajuste de otros hiperparámetros como el método de activación y la generación de Imagenes. En este segundo modelo, vamos vamos a cambiar la manera en la que generamos las imágenes. A pesar de que los resultados del primer modelo eran bastante buenos, queremos implementar algo que se tarde mucho menos.
"""

tr_gen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

ts_gen = ImageDataGenerator(rescale=1./255)

model2 = Sequential()

# Primer bloque convolucional
model2.add(Conv2D(32, (3, 3), input_shape=(img_size[0], img_size[1], 3), activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

# Segundo bloque convolucional
model2.add(Conv2D(64, (3, 3), activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

# Tercer bloque convolucional
model2.add(Conv2D(128, (3, 3), activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

# Cuarto bloque convolucional
model2.add(Conv2D(256, (3, 3), activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten para conectar a capas densas
model2.add(Flatten())

# Capa densa con 256 neuronas y activación relu
model2.add(Dense(256, activation='relu'))
model2.add(Dropout(0.5))  # Dropout para evitar el sobreajuste

# Capa de salida con activación softmax para la clasificación
model2.add(Dense(len(train_df['label'].unique()), activation='softmax'))

# Compilar el modelo
model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Muestra un resumen del modelo
model2.summary()

epochs = 5  # Ajusta el número de épocas según sea necesario

history = model2.fit(
    train_gen,
    steps_per_epoch=train_gen.n // batch_size,
    epochs=epochs,
    validation_data=valid_gen,
    validation_steps=valid_gen.n // batch_size
)

train_acc = history.history['accuracy']
train_loss = history.history['loss']

val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

index_loss = np.argmin(val_loss)
val_lowest = val_loss[index_loss]

index_acc = np.argmax(val_acc)
val_highest = val_acc[index_acc]

Epochs = [i+1 for i in range(len(train_acc))]

loss_label = f'Best epochs = {str(index_loss +1)}'
acc_label = f'Best epochs = {str(index_acc + 1)}'


plt.figure(figsize= (20,8))
plt.style.use('fivethirtyeight')

plt.subplot(1,2,1)
plt.plot(Epochs , train_loss , 'b' , label = 'Training Loss')
plt.plot(Epochs , val_loss , 'r' , label = 'Validation Loss')
plt.scatter(index_loss + 1 , val_lowest , s = 150 , c = 'green',label = loss_label)
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1,2,2)
plt.plot(Epochs , train_acc , 'b' , label = 'Training Accuracy')
plt.plot(Epochs , val_acc , 'r' , label = 'Validation Accuracy')
plt.scatter(index_acc + 1 , val_highest , s = 150 , c = 'green',label = acc_label)
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout
plt.show();

"""Finalmente, después de ver estos resultados, se decidió que lo mejor sería jugar con las capas y los hiperparámetros, respetando cómo se generaron las imágenes en el primer modelo. Esto se debe a que el modelo se tardó demasiado en correr, por lo que se perdió mucho tiempo trabajando en él.


"""

img_size = (224 ,244)
batch_size = 16

tr_gen = ImageDataGenerator()
ts_gen= ImageDataGenerator()

train_gen = tr_gen.flow_from_dataframe(train_df , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,
                                      class_mode = 'categorical' , color_mode = 'rgb' , shuffle = True , batch_size =batch_size)

valid_gen = ts_gen.flow_from_dataframe(valid , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,
                                       class_mode = 'categorical',color_mode = 'rgb' , shuffle= True, batch_size = batch_size)

test_gen = ts_gen.flow_from_dataframe(test , x_col= 'filepaths' , y_col = 'label' , target_size = img_size ,
                                      class_mode = 'categorical' , color_mode= 'rgb' , shuffle = False , batch_size = batch_size)

model3 = Sequential()

model3.add(Conv2D(32, (3, 3), input_shape=(img_size[0], img_size[1], 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))

model3.add(Conv2D(64, (3, 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))

model3.add(Flatten())

model3.add(Dense(128, activation='relu'))
model3.add(Dropout(0.5))

model3.add(Dense(len(train_df['label'].unique()), activation='softmax'))
# Compilar el modelo
model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Muestra un resumen del modelo
model3.summary()

epochs = 5  # Ajusta el número de épocas según sea necesario

history = model3.fit(
    train_gen,
    steps_per_epoch=train_gen.n // batch_size,
    epochs=epochs,
    validation_data=valid_gen,
    validation_steps=valid_gen.n // batch_size
)

train_acc = history.history['accuracy']
train_loss = history.history['loss']

val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

index_loss = np.argmin(val_loss)
val_lowest = val_loss[index_loss]

index_acc = np.argmax(val_acc)
val_highest = val_acc[index_acc]

Epochs = [i+1 for i in range(len(train_acc))]

loss_label = f'Best epochs = {str(index_loss +1)}'
acc_label = f'Best epochs = {str(index_acc + 1)}'


plt.figure(figsize= (20,8))
plt.style.use('fivethirtyeight')

plt.subplot(1,2,1)
plt.plot(Epochs , train_loss , 'b' , label = 'Training Loss')
plt.plot(Epochs , val_loss , 'r' , label = 'Validation Loss')
plt.scatter(index_loss + 1 , val_lowest , s = 150 , c = 'green',label = loss_label)
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1,2,2)
plt.plot(Epochs , train_acc , 'b' , label = 'Training Accuracy')
plt.plot(Epochs , val_acc , 'r' , label = 'Validation Accuracy')
plt.scatter(index_acc + 1 , val_highest , s = 150 , c = 'green',label = acc_label)
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout
plt.show();

"""# **Resultados**"""

# Evaluate the model on the test set
evaluation = model.evaluate(test_gen, steps=test_gen.n // batch_size)
print(f"Loss: {evaluation[0]:.2f}")
print(f"Accuracy: {evaluation[1]:.2f}")

# Evaluate the model on the test set
evaluation = model2.evaluate(test_gen, steps=test_gen.n // batch_size)
print(f"Loss: {evaluation[0]:.2f}")
print(f"Accuracy: {evaluation[1]:.2f}")

# Evaluate the model on the test set
evaluation = model3.evaluate(test_gen, steps=test_gen.n // batch_size)
print(f"Loss: {evaluation[0]:.2f}")
print(f"Accuracy: {evaluation[1]:.2f}")

# Choose a random test image
random_inx = np.random.choice(len(test_gen))
test_image, test_label = test_gen[random_inx]

# Display the test image
plt.axis('off')
plt.imshow(test_image[0], cmap='gray')  # Assuming it's a grayscale image
plt.show()

# Convert one-hot encoded label to scalar
true_label = np.argmax(test_label, axis=-1)
print(f"True Label: {test_gen.classes[true_label[0]]}")

# Get the model predictions
pred = model.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model Prediction: ", predicted_label)

# Choose a random test image
random_inx = np.random.choice(len(test_gen))
test_image, test_label = test_gen[random_inx]

# Display the test image
plt.axis('off')
plt.imshow(test_image[0], cmap='gray')  # Assuming it's a grayscale image
plt.show()

# Convert one-hot encoded label to scalar
true_label = np.argmax(test_label, axis=-1)
print(f"True Label: {test_gen.classes[true_label[0]]}")

# Get the model predictions
pred = model2.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model Prediction: ", predicted_label)

# Choose a random test image
random_inx = np.random.choice(len(test_gen))
test_image, test_label = test_gen[random_inx]

# Display the test image
plt.axis('off')
plt.imshow(test_image[0], cmap='gray')  # Assuming it's a grayscale image
plt.show()

# Convert one-hot encoded label to scalar
true_label = np.argmax(test_label, axis=-1)
print(f"True Label: {test_gen.classes[true_label[0]]}")

# Get the model predictions
pred = model3.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model Prediction: ", predicted_label)

# Get the model predictions
pred = model.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model: ", predicted_label)

# Get the model predictions
pred = model2.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model: ", predicted_label)

# Get the model predictions
pred = model3.predict(test_image)
predicted_label = labels[np.argmax(pred)]

print("Model: ", predicted_label)

# Check model's predictions for each possible class
df = pd.DataFrame(pred, columns=train_df['label'].unique())
df

# Visualize model's predictions
df.plot.bar()

"""# **Conclusiones**

Después de todos estos modelos creados, podemos llegar a la conclusión de que el mejor modelo que obtuvimos fue el tercer modelo, el que tenía menores capas.

Esto puede deberse a la optimización y tal vez exista un poco de overfitting en el primer modelo, a pesar de tener lo que parece ser un buen desempeño. Esto lo pudimos comprobar cuando vimos su desempeño en las contra las predicciones en las imagenes de Test.

Me parece que es importante recalcar que en primer instancia, podría parecer que el primer modelo y el último tienen resultados similares, sin embargo, debido a las capas, pudimos ver un mejor desempeño en este último.

Pienso que un área de oportunidad favorable podría ser jugar con el generador de imágenes, ya que mientras que dio el peor modelo, puede ser que exista algún parametro que podamos modificar que nos dé un mejor desempeño.

También sería bueno compararlo con un RNN, para comparar de manera experimental sus desempeños en el mismo data set.
"""